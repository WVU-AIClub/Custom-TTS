{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WVU-AIClub/Custom-TTS/blob/Sean-Branch/Piper/Piper_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulTkpdiGQjI4"
      },
      "source": [
        "0) Colab runtime + GPU check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y37QtlLmPuqT",
        "outputId": "8410c4bf-8f75-4b47-b6ff-49541712ca87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.10.12\n",
            "PyTorch: 2.9.1+cu128\n",
            "CUDA available: True\n",
            "Wed Nov 19 15:17:47 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4070 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   44C    P8              6W /   80W |      34MiB /   8188MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A            1351      G   /usr/lib/xorg/Xorg                        8MiB |\n",
            "|    0   N/A  N/A            1504      G   /usr/bin/gnome-shell                      3MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "voice_folder = \"Peter\"\n",
        "VOICE_NAME      = \"PETAH\"\n",
        "\n",
        "# Check GPU\n",
        "import torch, platform, sys\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRWDRJUpQrfw"
      },
      "source": [
        "1) System packages (incl. eSpeak dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN5lcQRZQs3D",
        "outputId": "c58a0d72-9585-4fab-adfb-dbc9706a867c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[sudo] password for aiwvu: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "sudo: a password is required\n",
            "^C\n",
            "[sudo] password for aiwvu: \n",
            "sudo: a password is required\n",
            "^C\n",
            "Package espeak-ng was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `espeak-ng.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'espeak-ng' found\n"
          ]
        }
      ],
      "source": [
        "# If not running on Google Colab. Run this yourself\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y build-essential cmake ninja-build espeak-ng espeak-ng-data libespeak-ng-dev pkg-config ffmpeg\n",
        "!pkg-config --modversion espeak-ng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_MRPygaQ1cQ"
      },
      "source": [
        "2) Clone repo fresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-0x1IWPQ7UB",
        "outputId": "9c003479-1f08-4383-a4d6-8c1b46c51903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'piper1-gpl'...\n",
            "remote: Enumerating objects: 817, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 817 (delta 176), reused 157 (delta 155), pack-reused 598 (from 4)\u001b[K\n",
            "Receiving objects: 100% (817/817), 4.69 MiB | 34.33 MiB/s, done.\n",
            "Resolving deltas: 100% (455/455), done.\n",
            "/home/aiwvu/Custom-TTS/piper1-gpl\n",
            "/home/aiwvu/Custom-TTS/piper1-gpl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aiwvu/Custom-TTS/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "!rm -rf piper1-gpl\n",
        "!git clone https://github.com/OHF-voice/piper1-gpl.git\n",
        "%cd piper1-gpl\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_qVUXtoRArT"
      },
      "source": [
        "3) Python deps (editable install, no venv in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ARM5C9RDZ_",
        "outputId": "c12a29d0-98d6-49b5-df1f-867449a989f6"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install --upgrade pip setuptools wheel\n",
        "!python3 -m pip install -e \".[train]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXkhMJRkRUGk"
      },
      "source": [
        "4) Build the Cython extension used for alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMQF3quvRVe7",
        "outputId": "ed352780-715b-47e9-e00f-76cc58b2bfb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'piper1-gpl/'\n",
            "/home/aiwvu/Custom-TTS/piper1-gpl\n",
            "Compiling /home/aiwvu/Custom-TTS/piper1-gpl/src/piper/train/vits/monotonic_align/core.pyx because it changed.\n",
            "[1/1] Cythonizing /home/aiwvu/Custom-TTS/piper1-gpl/src/piper/train/vits/monotonic_align/core.pyx\n",
            "performance hint: core.pyx:5:0: Exception check on 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n",
            "performance hint: core.pyx:36:0: Exception check on 'maximum_path_c' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_c' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_c' to allow an error code to be returned.\n",
            "performance hint: core.pyx:42:21: Exception check after calling 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n"
          ]
        }
      ],
      "source": [
        "%cd piper1-gpl\n",
        "!chmod +x ./build_monotonic_align.sh\n",
        "!./build_monotonic_align.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8P9iQhjRa81"
      },
      "source": [
        "5) Dev build (repo mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcRcqt6p3kM",
        "outputId": "d826ec7e-16ef-4bcb-b348-c018582ac8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /home/aiwvu/Custom-TTS/.venv/lib/python3.10/site-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /home/aiwvu/Custom-TTS/.venv/lib/python3.10/site-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /home/aiwvu/Custom-TTS/.venv/lib/python3.10/site-packages (0.45.1)\n",
            "Collecting scikit-build\n",
            "  Using cached scikit_build-0.18.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cmake\n",
            "  Using cached cmake-4.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting ninja\n",
            "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting distro (from scikit-build)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: packaging in /home/aiwvu/Custom-TTS/.venv/lib/python3.10/site-packages (from scikit-build) (25.0)\n",
            "Collecting tomli (from scikit-build)\n",
            "  Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Using cached scikit_build-0.18.1-py3-none-any.whl (85 kB)\n",
            "Using cached cmake-4.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (29.7 MB)\n",
            "Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tomli, ninja, distro, cmake, scikit-build\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [scikit-build][0m [cmake]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cmake-4.1.2 distro-1.9.0 ninja-1.13.0 scikit-build-0.18.1 tomli-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install --upgrade pip setuptools wheel scikit-build cmake ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTNUkZKmRcJb",
        "outputId": "bda670f9-575a-4904-c735-2193431127a4"
      },
      "outputs": [],
      "source": [
        "%cd /piper1-gpl\n",
        "!python3 setup.py build_ext --inplace -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRewWxitSmSr"
      },
      "source": [
        "7) Set paths and training hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyXNxSWFSq2u",
        "outputId": "2ce4e097-fa79-45be-d9cc-a7650e45925b"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# ==== CHANGE THESE ====\n",
        "\n",
        "ESPEAK_VOICE    = \"en-us\"  # run `!espeak-ng --voices` to see options\n",
        "SAMPLE_RATE_HZ  = 20250 # DEFAULT: 22050\n",
        "BATCH_SIZE      = 32       # drop to 8 or 4 if you OOM\n",
        "\n",
        "DATA_ROOT       = Path(f\"{voice_folder}\")\n",
        "AUDIO_DIR       = DATA_ROOT / \"wavs\"\n",
        "CSV_PATH        = DATA_ROOT / \"metadata.csv\"\n",
        "\n",
        "CACHE_DIR       = Path(f\"{voice_folder}/piper_cache\")\n",
        "CONFIG_PATH     = DATA_ROOT / f\"{VOICE_NAME}.json\"\n",
        "\n",
        "# Optional: start from an existing checkpoint to speed up & stabilize training\n",
        "# Get a .ckpt from https://huggingface.co/datasets/rhasspy/piper-checkpoints (medium quality recommended)\n",
        "CKPT_PATH       = \"\"  # e.g., \"/content/drive/MyDrive/piper_ckpts/en_US-lessac-medium.ckpt\"\n",
        "\n",
        "# Make sure dirs exist\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"CSV exists:\", CSV_PATH.exists())\n",
        "print(\"Audio dir exists:\", AUDIO_DIR.exists())\n",
        "print(\"Cache dir:\", CACHE_DIR)\n",
        "print(\"Config will be written to:\", CONFIG_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZqVTzcDSwRV"
      },
      "source": [
        "8) Quick sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPTTUbbxSydH",
        "outputId": "60357cd9-ab82-4c9d-8fa2-c35be4600843"
      },
      "outputs": [],
      "source": [
        "!espeak-ng --voices | head -n 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJImgsKzS1pk",
        "outputId": "91f04d81-8ab8-4ece-e987-04b4a698eba7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, os\n",
        "\n",
        "csv_path = str(CSV_PATH)\n",
        "if os.path.exists(csv_path):\n",
        "    # Read as pipe-delimited, two columns\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, sep=\"|\", header=None, names=[\"audio\",\"text\"])\n",
        "        print(df.head())\n",
        "        # Check a few audio files exist\n",
        "        missing = [a for a in df[\"audio\"].head(5) if not (AUDIO_DIR/str(a)).exists()]\n",
        "        print(\"Missing among first 5:\", missing)\n",
        "    except Exception as e:\n",
        "        print(\"CSV read error:\", e)\n",
        "else:\n",
        "    print(\"CSV not found at:\", csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiggGLHzTxGI"
      },
      "source": [
        "9) Kick off training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZigA3tIUSeh",
        "outputId": "20bf2e78-fc26-4e17-df35-ef52532aa241"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "train_cmd = [\n",
        "    sys.executable, \"-m\", 'piper.train fit',\n",
        "  \"--data.voice_name\", f\"{VOICE_NAME}\",\n",
        "  \"--data.csv_path\", f\"/{voice_folder}/metadata.csv\",\n",
        "  \"--data.audio_dir\", f\"/{voice_folder}/wavs\",\n",
        "  \"--model.sample_rate\", str(SAMPLE_RATE_HZ),\n",
        "  \"--data.espeak_voice\", f\"{ESPEAK_VOICE}\",\n",
        "  \"--data.cache_dir\", f\"/{voice_folder}/piper_cache\",\n",
        "  \"--data.config_path\", f\"/{voice_folder}/my_colab_voice.json\",\n",
        "  \"--data.batch_size\", str(BATCH_SIZE),\n",
        "  \"--ckpt_path\", \"https://huggingface.co/datasets/rhasspy/piper-checkpoints/resolve/main/en/en_US/lessac/medium/epoch%3D2164-step%3D1355540.ckpt\"\n",
        "]\n",
        "subprocess.run(train_cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSUfANcq7jUX"
      },
      "source": [
        "10. Export to onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX63f32Q7m98",
        "outputId": "39a5a5ef-49ba-4904-f5c9-53438c85326e"
      },
      "outputs": [],
      "source": [
        "# Checkpoint needs to be done dynamically\n",
        "export_cmd = [\n",
        "    sys.executable, \"-m\", \"piper.train.export_onnx\",\n",
        "  \"--checkpoint\", \"/piper1-gpl/lightning_logs/version_2/checkpoints/epoch=2174-step=2680.ckpt\",\n",
        "  \"--output-file\", f\"/{voice_folder}/model.onnx\"\n",
        "]\n",
        "subprocess.run(export_cmd, check=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.10.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
